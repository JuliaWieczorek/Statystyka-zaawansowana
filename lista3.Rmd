---
title: "lista 3"
output:
  html_notebook:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
---

# zad. 1 
W celu porównania dwóch różnych metod nauczania (klasycznej i innowacyjnej) 10-ciu losowo wybranych uczniów było najpierw nauczanych metodą klasyczną, a następnie podobny materiał był im przekazywany  metodą innowacyjną. Otrzymali oni następujące wyniki punktowe podczas testów:

```{r}
k <- c(65, 79, 90, 75, 61, 85, 98, 80, 97, 75)
n <- c(90, 98, 73, 79, 84, 81, 98, 90, 83, 88)
```

Czy na poziomie istotno±ci 0.05 możemy twierdzić, że zastosowane metody są porównywalne?



Te dane nie są z rozkładu normalnego, bo są typu skokowego! Poza tym powinno się to liczyć z całego wektora, a nie pojedynczo. Patrzymy na próbę, a nie na poszczególne próby danych.

Możemy przejść do wykonania wilcoxona.

H0: Średnie wyniki testów będą takie same.

HA: Średnie wyniki testów będą się różniły.

alfa = 0.05

```{r}
wilcox.test(k,n, paired=T)
```


Wartość p-value = 0.26 jest większa od założonej wartoci alfa = 0.05, zatem nie mamy podstaw do odrzcuenia hipotezy zerowej.

```{r message=TRUE, warning=TRUE}
ni=length(k) 
diff=n-k 
N=400 
sumoring=sum(diff) #suma roznic
stat=c() 
count=0 
for (i in 1:N){
  for (j in 1:ni){
    stat[j]=ifelse(runif(1)<0.5, diff[j], -diff[j])}
  if (sum(stat)>=sumoring) count=count+1
}
c=count/N 
if(c<=0.5){
  a=(c*2)
  print(a)
}else{
  b=(2-c*2)
  print(b)
}
```

```{r message=FALSE, warning=FALSE}
N=400 #liczba permutacji
ni=length(k) #ilosc par

dane_cale=cbind(k,n)
test=t.test(k,n,paired=TRUE,var.equal=TRUE)$statistic
counter=0 # licznik
for (i in 1: N ){
  for (j in 1: ni ){
    dane_cale[j,]=sample(dane_cale[j,],2)}
  test1<-wilcox.test(dane_cale[,1],dane_cale[,2],paired=TRUE,var.equal = TRUE)$statistic
  if (test1 >= test) {counter=counter+1}}
c <- counter/N
c
if(c<=0.5){
  a=(c*2)
  print(a)
}else{
  b=(2-c*2)
  print(b)
}
```


# zad. 2 
Pewien kierowca twierdzi, że z każdym rokiem jego auto zużywa więcej paliwa. Porównywał on liczbę przejechanych kilometrów po zatankowaniu 10 litrów paliwa teraz i przed dwoma laty.

```{r}
r2015 <- c(141.85, 134.36, 131.87, 137.28, 122.72, 136.44, 128.96, 136.86)
r2017 <- c(125.10, 122.00, 123.10, 119.92, 124.11, 121.91, 122.00, 135.95, 127.10, 125.10)
```

Zwerykowa¢ czy jego przypuszczenie jest słuszne.


H0: Dane dotyczące średniej liczby przejechanych kilometrów w 2015 roku pochodzi z r. norm.

HA: Dane dotyczące średniej liczby kilometrów w 2015 roku nie pochodzi z r. norm.

alfa = 0.05

```{r}
shapiro.test(r2015)
```

Wartość p jest większa od założonej wartości alfa, zatem nie mamy podstaw do odrzucenia hipotezy zerowej. Dane pochodzą z rozkładu normalnego.

H0: Dane dotyczące średniej liczby przejechanych kilometrów w 2017 roku pochodzi z r. norm.

HA: Dane dotyczące średniej liczby kilometrów w 2017 roku nie pochodzi z r. norm.

alfa = 0.05

```{r}
shapiro.test(r2017)
```

Wartość p jest mniejsza od założonej wartości alfa. Dane dotyczące średniej liczby kilometrów w 2017 roku nie pochodzi z rozkładu normalnego. 

```{r}
var2(r2015, r2017)
```


H0: Liczba przejechanych kilometrów w 2017 roku po zatankowaniu 10 litrów paliwa wynosi tyle samo, co w 2015roku

HA: Liczba przejechanych kilometrów w 2017 roku po zatankowaniu 10 litrów paliwa wynosi mniej niż w 2015roku

alfa = 0.05
```{r message=FALSE, warning=FALSE}
m <- length (r2015)
n <- length (r2017)
N <- 400 #liczba permutacji

test = wilcox.test(r2015, r2017, alternative = 'less')$statistic
test
counter = 0 
z=c(r2015, r2017)
combin = combn((m+ n), m) #macierz możliwości

for (i in 2: N){ # od i=2
  x1 <-z[combin[,i]]     
  y1 <-z[-combin[,i]]  
  test2 = wilcox.test(x1,y1, alternative = 'less')$statistic
  if( test2 >= test ){ counter = counter+1}  #porównanie statystyk 
}

counter/N
```

Wartość p jest większa od założonej wartosci alfa, zatem nie mamy postaw do odrzucenia hipotezy zerowej. Liczba przejechanych kilometrów w 2017 roku po zatankowaniu 10 litrów paliwa wynosi tyle samo, co w 2015roku.


# zad. 3 
Rozważyć powyższe zadanie w sytuacji gdyby kierowca twierdził, że po dwóch latach użytkowania auta na tej samej ilości paliwa przejeżdża o około 10% kilometrów mniej.

```{r}
wynik=(((sum(r2015))/(length(r2015)))*100)/((sum(r2017))/(length(r2017)))
wynik
```

7% więcej przejechanych kilometrów w 2015 roku.


H0: 2015r x km = 2017 0.9x km
HA: 2015r x km != 2017 0.9x km

```{r message=FALSE, warning=FALSE}
dane <- r2015*0.9
shapiro.test(dane) #pochodzi z rozkladu normalnego
N <- 400 
n <- length(dane)
m <- length(r2017)
suma <- sum(dane)

test1 <- wilcox.test(r2015, dane)$statistic #wg dokumentacji tzn 2-gi wieksze od 1-go argumentu
cnt <- 0 # licznik, zwiększany indykator
z <- c(dane,r2015) #oba zbiory w jeden wektor
combin <- combn((m+n),m) #macierz wszystkich kombinacji m-elementowych ze zbioru m+n-elementowego
for (i in 2:N){ #od i=2, bo 
  nx1 <- z[combin[,i]] 
  ny1 <- z[-combin[,i]] 
  test2 <- wilcox.test(nx1,ny1)$statistic
  if(test2 <= test1){cnt=cnt+1} #wzrost indykatora, gdy prawdziwa nierówność
}
c <- cnt/N
c
if(c<=0.5){
  a=(c*2)
  print(a)
}else{
  b=(2-c*2)
  print(b)
}
```


# zad. 4
Wygeneruj próbe 100 par obserwacji z dwuwymiarowego rozkładu normalnego ze średnią μ = (0, 0) i macierzą kowariancji Σ = I. Wyznacz 95% bootstrapowe przedziaay ufności dla współczynnikóW korelacji.

```{r message=FALSE, warning=FALSE}
library(mvtnorm)
set.seed(1)
a<-matrix(rmvnorm(100, mean(0,0)), ncol=2)
n<-50

library(bootstrap)

theta <- function(x, a){
  cor(a[x,1], a[x,2])
}
przedzial <- boott(1:n, theta, a, perc=c(0.05, 0.95), nbootsd = 60, nboott = 200)
przedzial[1]
#nbootsd -> bootstrap od thety
#nboott -> bootstap przedzialu
```


```{r}
#a<-matrix(rmvnorm(100, mean(0,0)), ncol=2)
N <- 50
stat <- numeric(N)
IQR <- numeric(N)

for (i in 1: N){
  z <- matrix(sample(a, replace=T), ncol=2, nrow=length(a)/2)
  stat[i] <- cor(z[,1], z[,2])
  #IQR [i] <- qnorm(0.995, 1/mean(z))-qnorm(0.25, 1/mean(z))
}

quantile(stat, c(0.05, 0.95))
#quantile(IQR, c(0.05 ,0.95))
```


```{r}
statS <- numeric (N)
h <-0.5
for (i in 1: N){
  z <- sample (x , replace =T )
  s <-(sum ((z - mean (z )) ^2) )/ length ( z)
  x.new <-mean ( z) +(z - mean (z)+ h* rnorm ( length (z)))/ sqrt (1+(( h^2) /( s)))
  statS [i] <- median (x.new)
}
quantile ( statS , c (0.05 , 0.95) )
```


```{r}
library(mvtnorm)
dane=rmvnorm(n=100,mean=c(0,0))
cor.test(dane[,1],dane[,2])
N=500
przedzialy=matrix(nrow=N,ncol=2)
colnames(przedzialy)=c("Lewy","Prawy")
for (i in 1:N){
  dane=rmvnorm(n=100,mean=c(0,0))
  przedzialy[i,1]=cor.test(dane[,1],dane[,2])$conf[1]
  przedzialy[i,2]=cor.test(dane[,1],dane[,2])$conf[2]
}
mean(przedzialy[,1])
mean(przedzialy[,2])
```

